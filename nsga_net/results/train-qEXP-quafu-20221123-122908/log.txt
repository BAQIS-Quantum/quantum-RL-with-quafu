2022-11-23 12:29:08,843 args = Namespace(arch='NSGANet_id97', batch_size=1, env_name='CartPole-v1', epochs=1, gamma=1.0, infer_episodes=5, n_actions=2, n_episodes=20, n_qubits=4, save='train-qEXP-quafu-20221123-122908', state_bounds=array([2.4 , 2.5 , 0.21, 2.5 ]))
2022-11-23 12:29:10,805 epoch 0
2022-11-23 12:42:52,191 ['1AE789802167D19F', '1AE78AE01607FFD9', '1AE78C000B9C03F1', '1AE78D30027B298E', '1AE78E502F016E99', '1AE78F80271DA046', '1AE790A01C570141', '1AE791D00F57B816', '1AE7930028582BB8', '1AE794401E7E751F', '1AE79570175213D6', '1AE796A02D4E2118', '1AE797E022A92756', '1AE799101909F14F', '1AE79A400FA5766F', '1AE79B60011FFAA6', '1AE79C70337975B0', '1AE79DB015D3A968', '1AE79EF00EE4AEE1', '1AE7A020000F3E57', '1AE7A13030C9E228', '1AE7A260270355CF', '1AE7A390057FBAE8', '1AE7A4B03266FC10', '1AE7A5C0297098C9', '1AE7A6F0209BF61E', '1AE7A81011ECE9B9', '1AE7A920065421E6', '1AE7AA30373AF636', '1AE7AB70133D7DC8', '1AE7AC9003BBE307', '1AE7ADA0357B585F', '1AE7AEB029540C30', '1AE7AFD01FB07511', '1AE7B0E00EF12A31', '1AE7B200041EFE1E', '1AE7B31039AEA1D0', '1AE7B420303A86F0', '1AE7B5400B5AA58F', '1AE7B66000FED25F', '1AE7B7603375DBCF', '1AE7B870256E561F', '1AE7B9901CF014BF', '1AE7BAA0140ADC01', '1AE7BBC00A6C4A08']
2022-11-23 12:42:53,611 train finished episode: 1.000000
2022-11-23 12:42:53,611 train average rewards: 45.000000
2022-11-23 12:48:56,803 ['1AE7BCF039E71AD6', '1AE7BDF031755C99', '1AE7BF10270FE0C0', '1AE7C0201C2C14F9', '1AE7C1400C2E975E', '1AE7C26000BEB068', '1AE7C3701A0F6EB9', '1AE7C480116867D7', '1AE7C58001E46BB6', '1AE7C6803265F26E', '1AE7C78028373A21', '1AE7C8801D5118B0', '1AE7C9700CD0941E', '1AE7CA500013497E', '1AE7CB2031C11F21', '1AE7CBF01EDAF4D0', '1AE7CCC01421AFBF', '1AE7CD9007A0D9B1', '1AE7CE401E27FC66', '1AE7CEF00E4219C8', '1AE7CFB00169639E', '1AE7D050314EFC5E', '1AE7D110261ED1D1', '1AE7D1B011F60D8E', '1AE7D260049FD298', '1AE7D2F0328F8311']
2022-11-23 12:48:57,247 train finished episode: 2.000000
2022-11-23 12:48:57,247 train average rewards: 26.000000
2022-11-23 12:52:01,105 ['1AE7D3B00059A920', '1AE7D4600F6A22EF', '1AE7D4E001497BA8', '1AE7D60034915239', '1AE7D720235EB7D0', '1AE7D85018B7CDF7', '1AE7D9700EDE3E70', '1AE7DA9007D4DA31', '1AE7DBB033E93EDF', '1AE7DCE02B96B4E9', '1AE7DE10042B42C1']
2022-11-23 12:52:01,618 train finished episode: 3.000000
2022-11-23 12:52:01,619 train average rewards: 11.000000
2022-11-23 13:05:34,451 ['1AE7DF3016755037', '1AE7E0500AC45516', '1AE7E1703B8D9EE7', '1AE7E29032178839', '1AE7E3C022C7EE40', '1AE7E4F01DC30C90', '1AE7E610138E8011', '1AE7E730062FB996', '1AE7E8601827E61E', '1AE7E98030F33447', '1AE7EAA025D31716', '1AE7EBC0169301C9', '1AE7ECF00BFD6D6E', '1AE7EE1003C3BEBE', '1AE7EF3035061CA9', '1AE7F0502569F507', '1AE7F1801A3653C1', '1AE7F2B01244A2BF', '1AE7F3D0083BF4B8', '1AE7F4E036B96E10', '1AE7F6102EAB6729', '1AE7F740255F1F98', '1AE7F8601C5BC401', '1AE7F9800E898AD9', '1AE7FAB0032F75D1', '1AE7FBC03552C990', '1AE7FCF02C98F246', '1AE7FE101C20E1C7', '1AE7FF40142011B0', '1AE800700B7ED730', '1AE8018039520AAE', '1AE802B0314B79EF', '1AE803D028BE446E', '1AE805102C889E96', '1AE806401E98BBB0', '1AE80770143A9AA7', '1AE808900A416977', '1AE809B0380F3A10', '1AE80AE02E571150', '1AE80C00250C7B59', '1AE80D301C9AE80E', '1AE80E600F0CB10E', '1AE80FA02439BA37', '1AE810D01AB70128']
2022-11-23 13:05:34,926 train finished episode: 4.000000
2022-11-23 13:05:34,926 train average rewards: 44.000000
2022-11-23 13:08:02,602 ['1AE812002F92C988', '1AE8132020522B81', '1AE8145016B47C18', '1AE815700DE9A928', '1AE816A00561C6EF', '1AE817C0340D93A8', '1AE818F02C62BF49', '1AE81A1023B00069']
2022-11-23 13:08:03,036 5 out of the last 5 calls to <function train.<locals>.reinforce_update at 0x7f877209fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2022-11-23 13:08:03,036 train finished episode: 5.000000
2022-11-23 13:08:03,037 train average rewards: 8.000000
2022-11-23 13:12:08,313 ['1AE81B4034DED20E', '1AE81C6025ECE877', '1AE81DA02C0CEA9F', '1AE81EE022C857B9', '1AE820101654F311', '1AE821300F706097', '1AE822602C08665F', '1AE823802390A8F7', '1AE824B016654AA8', '1AE825E02CC1C769', '1AE82720235D024F', '1AE828501D5713EE', '1AE8297010A38D4E']
2022-11-23 13:12:08,794 6 out of the last 6 calls to <function train.<locals>.reinforce_update at 0x7f877209fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2022-11-23 13:12:08,795 train finished episode: 6.000000
2022-11-23 13:12:08,795 train average rewards: 13.000000
2022-11-23 13:26:36,779 ['1AE82AA025D20D78', '1AE82BC01CF7581E', '1AE82CF01495802F', '1AE82E202A945849', '1AE82F602102CE3E', '1AE830A000323B61', '1AE831B0397F9AC1', '1AE832D030F468DE', '1AE8340027200591', '1AE835301E479E0F', '1AE83660124260A1', '1AE83780089DFA76', '1AE838B0211665E1', '1AE839C01946D727', '1AE83AD00AE14B28', '1AE83BF0032AC698', '1AE83CF03432EE28', '1AE83E202BBF7E51', '1AE83F401CE7C3D8', '1AE840501395C756', '1AE841702E82B919', '1AE842A02320B0E8', '1AE843C01993E5B7', '1AE844E010BA2A61', '1AE845F008B57247', '1AE846F035B59E57', '1AE848102E36CB98', '1AE8492025141890', '1AE84A401D8F331F', '1AE84B600CECF5BF', '1AE84C70023EA55E', '1AE84D80384CA0CF', '1AE84E902FB87226', '1AE84FB02079FAE8', '1AE850C01529C539', '1AE851E00A53303E', '1AE852F000001387', '1AE854002D6A05B8', '1AE85510235CBBFE', '1AE8563039C5E6D8', '1AE857402B27264F', '1AE8586020729461', '1AE8597015AAD449', '1AE85A90077A1BB8', '1AE85BA020A48D59', '1AE85CB01622D6F1', '1AE85DD00CF07FFE', '1AE85ED0394214C0', '1AE85FD0305D0AE0']
2022-11-23 13:26:37,287 train finished episode: 7.000000
2022-11-23 13:26:37,288 train average rewards: 49.000000
2022-11-23 13:28:53,021 ['1AE860F0089EC598', '1AE861F03A74C477', '1AE863000AD4EF17', '1AE863E03AB0A87E', '1AE864C02EE52466', '1AE865A01D595DE0', '1AE8667010AE1C71', '1AE867300558CE0F', '1AE867F034C0C2BE', '1AE868C005E231F0']
2022-11-23 13:28:53,502 train finished episode: 8.000000
2022-11-23 13:28:53,502 train average rewards: 10.000000
2022-11-23 13:31:08,269 ['1AE86970152DB8EE', '1AE86A200784E570', '1AE86AC0358EB17E', '1AE86B702315C021', '1AE86C1014D7D4A7', '1AE86CC009CBF328', '1AE86D503A7BF838', '1AE86E00100AE730', '1AE86E900168F63F', '1AE86F2016047980', '1AE86FB0026D5A67', '1AE87010365689A9', '1AE870A00AD19B87', '1AE8710032FED711', '1AE8718014E968A8']
2022-11-23 13:31:08,694 train finished episode: 9.000000
2022-11-23 13:31:08,695 train average rewards: 15.000000
2022-11-23 13:32:33,850 ['1AE871F004CE50F0', '1AE872402CA72AE7', '1AE872B01CE1A959', '1AE873200EEEEFDF', '1AE873803ADDF240', '1AE873F02769B8C0', '1AE874601A2FDF66', '1AE874C00BB89857', '1AE875203A67B0CF', '1AE8759027B538E1', '1AE8760017DFE870', '1AE8767009654216', '1AE876D03730D090']
2022-11-23 13:32:33,886 train finished episode: 10.000000
2022-11-23 13:32:33,886 train average rewards: 13.000000
2022-11-23 13:33:40,859 ['1AE8773026943C66', '1AE877A01A850C17', '1AE878100D68FBC1', '1AE8788000DEC741', '1AE878E0293D4428', '1AE879501A09D520', '1AE879C00B9001B8', '1AE87A301BC42396', '1AE87A900AFA7876', '1AE87AF038961D4E']
2022-11-23 13:33:40,888 train finished episode: 11.000000
2022-11-23 13:33:40,888 train average rewards: 10.000000
2022-11-23 13:35:57,964 ['1AE87B602BFAAEA8', '1AE87BD017BEBC3F', '1AE87C4007C0F471', '1AE87C9032C11676', '1AE87D0023A51F3F', '1AE87D700DA03860', '1AE87DE02086B0CE', '1AE87E40114CF096', '1AE87EA038173509', '1AE87F200F984F41', '1AE87F8002BF376E', '1AE87FE0317A0FB9', '1AE880501E685CDE', '1AE880C00F18B72E', '1AE8813000377F08', '1AE8819013E65C3F', '1AE881E039DF3F1F', '1AE882502AE94676', '1AE882C01E8F268E', '1AE88330131C8076', '1AE88390019A4357']
2022-11-23 13:35:58,508 train finished episode: 12.000000
2022-11-23 13:35:58,508 train average rewards: 21.000000
2022-11-23 13:40:24,415 ['1AE884001685ABB8', '1AE884700AE76D78', '1AE884C03067E050', '1AE88530201E9860', '1AE885A01127A99E', '1AE886201F4C96A9', '1AE886900B6D00C8', '1AE886F03AC68A10', '1AE88760266EA750', '1AE887C01A857590', '1AE88830091E3698', '1AE888903658F2D6', '1AE888F027EF4059', '1AE88960147B0ABF', '1AE889D0058CC2D8', '1AE88A4019E107CE', '1AE88AC00B760949', '1AE88B3016BB4E31', '1AE88B900640306E', '1AE88C001E84D209', '1AE88C80104F9D08', '1AE88CE039DADE07', '1AE88D502B437468', '1AE88DD02A11B6E1', '1AE88E4019D7FB67', '1AE88EB00CE68938', '1AE88F10227D5498', '1AE88F8032719EB6', '1AE890001DE7B361', '1AE890700ED5D22E', '1AE890C0399593C0', '1AE891302752D560', '1AE891A01A3DA6C1', '1AE892000D66C556', '1AE892603A5B1258', '1AE892D026427AB6', '1AE8935037756341', '1AE893C029E2FA08', '1AE894301C7293D9']
2022-11-23 13:40:24,947 train finished episode: 13.000000
2022-11-23 13:40:24,947 train average rewards: 39.000000
2022-11-23 13:41:57,194 ['1AE894A02993A186', '1AE895001C3D5EBF', '1AE895702FC5C067', '1AE895F020B8F400', '1AE896600EB3B7B7', '1AE896C024484CB0', '1AE8972017F5D99F', '1AE89790073D263F', '1AE897F0346C7C86', '1AE8986027592E60', '1AE898D003C10F40', '1AE899302B5CDC50', '1AE899A01F6D8840', '1AE89A00120F6DA9']
2022-11-23 13:41:57,555 train finished episode: 14.000000
2022-11-23 13:41:57,556 train average rewards: 14.000000
2022-11-23 13:43:41,047 ['1AE89A701854D608', '1AE89AE005A914D8', '1AE89B40328A04D0', '1AE89BA0235B25BF', '1AE89C100F59041E', '1AE89C8003A55D66', '1AE89CE0307B701F', '1AE89D500B6FFE67', '1AE89DA033FDFF5E', '1AE89E200A21F2C7', '1AE89E7038C6D20E', '1AE89EE02B000E7E', '1AE89F5034F9B8C7', '1AE89FB02557EFC0', '1AE8A020174D0AC9', '1AE8A090087A8456']
2022-11-23 13:43:41,491 train finished episode: 15.000000
2022-11-23 13:43:41,491 train average rewards: 16.000000
2022-11-23 13:44:52,719 ['1AE8A0F00EFD14F8', '1AE8A1600472F638', '1AE8A1C031D2C6A6', '1AE8A2201EEF6EFF', '1AE8A29010D1B1CF', '1AE8A2F006052EF6', '1AE8A350320E4138', '1AE8A3C01D7CEF58', '1AE8A43010F24D79', '1AE8A4900233BC68', '1AE8A4F0310489C8']
2022-11-23 13:44:52,750 train finished episode: 16.000000
2022-11-23 13:44:52,750 train average rewards: 11.000000
2022-11-23 13:45:56,779 ['1AE8A5601F4E9E31', '1AE8A5C010BC6899', '1AE8A630033D44F9', '1AE8A6802D5AE69E', '1AE8A6F01DCED430', '1AE8A76010B62707', '1AE8A7C0034C2978', '1AE8A8202DA0F04F', '1AE8A8A006A998CE', '1AE8A8F03421D340']
2022-11-23 13:45:56,818 train finished episode: 17.000000
2022-11-23 13:45:56,819 train average rewards: 10.000000
2022-11-23 13:47:28,119 ['1AE8A96027B7FBE6', '1AE8A9E0196655A8', '1AE8AA500A8B3418', '1AE8AAB03848D03E', '1AE8AB102B489101', '1AE8AB80174411E9', '1AE8ABE00951C9B9', '1AE8AC40375C12C7', '1AE8ACB0234D6E09', '1AE8AD1012DD9AE6', '1AE8AD8003540530', '1AE8ADE02B700690', '1AE8AE401BBBC30E', '1AE8AEB00D1D9ADE']
2022-11-23 13:47:28,154 train finished episode: 18.000000
2022-11-23 13:47:28,155 train average rewards: 14.000000
2022-11-23 13:49:05,309 ['1AE8AF200082B8D9', '1AE8AF70275A4F6F', '1AE8AFE0173252EF', '1AE8B0502CCF92A7', '1AE8B0B01C856828', '1AE8B12008685BE7', '1AE8B1901EF6F8AF', '1AE8B210115F24C0', '1AE8B2700293CA3F', '1AE8B2D02A05D3E6', '1AE8B3301DC25CC7', '1AE8B3A00F2F9E77', '1AE8B3F03792C6AE', '1AE8B460293145D6', '1AE8B4D019925B2F']
2022-11-23 13:49:05,344 train finished episode: 19.000000
2022-11-23 13:49:05,345 train average rewards: 15.000000
2022-11-23 13:49:58,914 ['1AE8B5300B4DB126', '1AE8B5B022D6849F', '1AE8B62013A236EE', '1AE8B69006E818CF', '1AE8B6E02DFC377F', '1AE8B7501E7B9AA9', '1AE8B7C00F29B2D7', '1AE8B820013EB5D6']
2022-11-23 13:49:58,941 train finished episode: 20.000000
2022-11-23 13:49:58,941 train average rewards: 8.000000
